{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de parámetros, validación y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos algoritmos tienen asociados algunos parámetros que influyen en la complejidad del modelo que pueden aprender. Recuerda cuando usamos `KNeighborsRegressor`. Si cambiamos el número de vecinos a considerar, obtenemos progresivamente predicciones más y más *suavizadas*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura anterior, podemos ver ajustes con tres valores diferentes para ``n_neighbors``. Con ``n_neighbors=2``, los datos se sobreajustan, el modelo es muy flexible y ajusta demasiado bien el ruido que hay presente en el dataset. Para ``n_neighbors=20``, el modelo no es suficientemente flexible y no puede ajustar la variación en los datos.\n",
    "\n",
    "En la subfigura intermedia, hemos encontrado un buen punto intermedio, ``n_neighbors = 5``. Ajusta los datos bastante bien y no sufre ni de sobre-aprendizaje ni de infra-aprendizaje. Nos gustaría disponer de un método cuantitativo para identificar tanto el sobre-entrenamiento como el infra-entrenamiento y optimizar los hiperparámetros (en este caso, el número de vecinos) para llegar a los mejores resultados.\n",
    "\n",
    "Intentamos obtener un equilibrio entre recordar particularidades (y ruido) de los datos de entrenamiento y modelar la suficiente variabilidad de los mismos. Este equilibrio necesita obtenerse para cualquier algoritmo de aprendizaje automático y es un concepto central, denominado equilibrio bias-varianza o \"sobre-ajuste Vs. infra-ajuste\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros, sobre-ajuste e infra-ajuste\n",
    "\n",
    "Desafortunadamente, no hay un regla general para conseguir llegar a este punto óptimo y, por ello, el usuario debe encontrar el mejor equilibrio posible entre complejidad del modelo y generalización, probando distintas opciones para los hiper-parámetros. Los hiper-parámetros son aquellos parámetros que podemos ajustar sobre un algoritmos de aprendizaje automático (algoritmo que, a su vez, ajusta los parámetros del modelo en función de los datos de entrenamiento, de ahí el \"hiper\"). El número de vecinos $k$ del algoritmo kNN es un hiper-parámetro.\n",
    "\n",
    "A menudo este ajuste de hiper-parámetros se hace mediante una búsqueda por fuerza bruta, por ejemplo usando varios valores de ``n_neighbors``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, rendimiento medio: 0.599320\n",
      "n_neighbors: 3, rendimiento medio: 0.723206\n",
      "n_neighbors: 5, rendimiento medio: 0.776378\n",
      "n_neighbors: 10, rendimiento medio: 0.740100\n",
      "n_neighbors: 20, rendimiento medio: 0.636805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Generamos un dataset sintético:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# Para cada parámetro, repetimos una validación cruzada\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, rendimiento medio: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una función en scikit-learn, llamada ``validation_plot``, que produce una figura similar a la que vimos previamente. Representa un parámetro, como el número de vecinos, enfrentado a los errores de entrenamiento y validación (utilizando validación cruzada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njPGypGCMMcbr/wFRF74stEkAAAACSURBVLRV51NzfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2775b4a8080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"precisión de entrenamiento\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"precisión de test\")\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Número de vecinos')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si más de un parámetro es importante, como los parámetros ``C`` y ``gamma`` de una máquina de vectores soporte (SVM) (de las cuales hablaremos después), se intentan todas las posibles combinaciones de parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, valor medio de R^2: -0.145519\n",
      "C: 0.001000, gamma: 0.010000, valor medio de R^2: -0.027593\n",
      "C: 0.001000, gamma: 0.100000, valor medio de R^2: 0.001921\n",
      "C: 0.001000, gamma: 1.000000, valor medio de R^2: -0.027376\n",
      "C: 0.010000, gamma: 0.001000, valor medio de R^2: -0.003279\n",
      "C: 0.010000, gamma: 0.010000, valor medio de R^2: -0.003926\n",
      "C: 0.010000, gamma: 0.100000, valor medio de R^2: 0.052934\n",
      "C: 0.010000, gamma: 1.000000, valor medio de R^2: 0.059480\n",
      "C: 0.100000, gamma: 0.001000, valor medio de R^2: -0.076745\n",
      "C: 0.100000, gamma: 0.010000, valor medio de R^2: 0.129753\n",
      "C: 0.100000, gamma: 0.100000, valor medio de R^2: 0.473423\n",
      "C: 0.100000, gamma: 1.000000, valor medio de R^2: 0.474326\n",
      "C: 1.000000, gamma: 0.001000, valor medio de R^2: 0.122450\n",
      "C: 1.000000, gamma: 0.010000, valor medio de R^2: 0.575555\n",
      "C: 1.000000, gamma: 0.100000, valor medio de R^2: 0.666637\n",
      "C: 1.000000, gamma: 1.000000, valor medio de R^2: 0.685324\n",
      "C: 10.000000, gamma: 0.001000, valor medio de R^2: 0.595217\n",
      "C: 10.000000, gamma: 0.010000, valor medio de R^2: 0.573028\n",
      "C: 10.000000, gamma: 0.100000, valor medio de R^2: 0.684090\n",
      "C: 10.000000, gamma: 1.000000, valor medio de R^2: 0.765943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Hacer validación cruzada para cada combinación de parámetros:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, valor medio de R^2: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esto es algo que se hace frecuentemente en aprendizaje automático, hay una clase ya implementada en scikit-learn, ``GridSearchCV``. ``GridSearchCV`` utiliza un diccionario que describe los parámetros que deberían probarse y un modelo que entrenar.\n",
    "\n",
    "La rejilla de parámetros se define como un diccionario, donde las claves son los parámetros y los valores son las cantidades a probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las cosas interesantes de GridSearchCV es que es un *meta-estimador*. Utiliza un estimador como SVR y crea un nuevo estimador que se comporta exactamente igual que SVR, por lo que podemos llamar a ``fit`` para entrenarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.09366760335626667, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] .... C=0.001, gamma=0.001, score=-0.09054020491184, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.0035556705750121593, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.09155434030036114, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.08827327118796013, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=-0.0016305372666962636, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=-0.08186005656720874, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .... C=0.001, gamma=0.1, score=-0.0778225309793743, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=0.006914108312099931, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.08319540428472116, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.07980285167538459, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=0.005845253232461656, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=-0.09135399176032255, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ... C=0.01, gamma=0.001, score=-0.0880193984352533, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.001437648403978864, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=-0.0704088834882024, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=-0.06233484276730938, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ..... C=0.01, gamma=0.01, score=0.0183448129318875, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .... C=0.01, gamma=0.1, score=0.020266426166135165, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.04158331650669844, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.09927187585652308, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ...... C=0.01, gamma=1, score=0.007910296370050474, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.01411759966162296, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ........ C=0.01, gamma=1, score=0.0846378668630714, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=-0.06844101626331844, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=-0.05957044352893304, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.020388395735927767, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.0975724002872318, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.15126964859808478, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.1745160812031259, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.4539717578090438, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5048394059853212, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5356836404693478, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .......... C=0.1, gamma=1, score=0.445893928873002, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ........ C=0.1, gamma=1, score=0.38072234526031024, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4835018245594117, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.11404368512943308, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.1617148000359553, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.18363427941332477, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ....... C=1, gamma=0.01, score=0.49543110517412586, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6113148011716693, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6622215506090234, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.5854829328585043, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6549549591693117, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.7610051028202105, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6680241400540428, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6558362152532994, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7981175217943164, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.4971637318051136, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6222641904127318, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6632884525781131, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.5368219794700677, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6510504868205265, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.7083258438150458, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.5910546262100405, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.644589019395376, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.7612876222002694, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7318928830009032, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.6850115898782383, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8226511092832511, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``GridSearchCV`` aplica un proceso algo más complejo que el visto anteriormente. Primero, ejecuta el mismo bucle de validación cruzada para encontrar la mejor combinación de parámetros. Una vez tiene la mejor combinación, ejecuta el método ``fit`` de nuevo sobre todos los datos que se le pasan (sin validación cruzada), para construir un nuevo modelo con los parámetros óptimos obtenidos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, utilizando los métodos ``predict`` o ``score`` podemos realizar una nueva predicción:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Puedes observar los mejores parámetros obtenidos por ``GridSearchCV`` en su atributo ``best_params_`` y la puntuación correspondiente en su atributo ``best_score_``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746372270944\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero puedes investigar más a fondo el rendimiento y algunas cosas más sobre cada una de las combinaciones de parámetros accediendo al atributo `cv_results_`. `cv_results_` es un diccionario donde cada clave es una cadena y cada valor un array. Se puede por tanto usar para crear un ``DataFrame`` de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.deprecation.DeprecationDict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>-0.062899</td>\n",
       "      <td>-0.003377</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.093668</td>\n",
       "      <td>-0.010460</td>\n",
       "      <td>-0.090540</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-0.003556</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.005009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>-0.060797</td>\n",
       "      <td>-0.001381</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.091554</td>\n",
       "      <td>-0.008121</td>\n",
       "      <td>-0.088273</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>-0.001631</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.041545</td>\n",
       "      <td>0.004766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>-0.051232</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.081860</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>-0.077823</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.040841</td>\n",
       "      <td>0.003972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>-0.052692</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.083195</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>-0.079803</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.041106</td>\n",
       "      <td>0.004445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>-0.060581</td>\n",
       "      <td>-0.001182</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.091354</td>\n",
       "      <td>-0.007875</td>\n",
       "      <td>-0.088019</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>-0.001438</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.041530</td>\n",
       "      <td>0.004732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.002973         0.002008        -0.062899         -0.003377   0.001   \n",
       "1       0.002006         0.001319        -0.060797         -0.001381   0.001   \n",
       "2       0.002012         0.001663        -0.051232          0.007540   0.001   \n",
       "3       0.002005         0.001007        -0.052692          0.006578   0.001   \n",
       "4       0.001661         0.001339        -0.060581         -0.001182    0.01   \n",
       "\n",
       "  param_gamma                        params  rank_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}               20   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}               19   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}               16   \n",
       "3           1      {'C': 0.001, 'gamma': 1}               17   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}               18   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0          -0.093668           -0.010460          -0.090540   \n",
       "1          -0.091554           -0.008121          -0.088273   \n",
       "2          -0.081860            0.001924          -0.077823   \n",
       "3          -0.083195            0.000310          -0.079803   \n",
       "4          -0.091354           -0.007875          -0.088019   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.000123          -0.003556            0.000208      0.000043   \n",
       "1            0.001939          -0.001631            0.002038      0.000012   \n",
       "2            0.010471           0.006914            0.010225      0.000015   \n",
       "3            0.010130           0.005845            0.009293      0.000009   \n",
       "4            0.002108          -0.001438            0.002219      0.000468   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000011        0.041667         0.005009  \n",
       "1        0.000463        0.041545         0.004766  \n",
       "2        0.000470        0.040841         0.003972  \n",
       "3        0.000011        0.041106         0.004445  \n",
       "4        0.000466        0.041530         0.004732  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, hay un problema en la utilización de este rendimiento para la evaluación. Puedes estar incurriendo en lo que se denomina un error de probar varias hipótesis. Si tienes muchas combinaciones de parámetros, algunas de ellas puede ser que funcionen mejor solo por aleatoriedad y que el rendimiento que estás obteniendo no sea el mismo cuando tengamos nuevos datos. Por tanto, es en general buena idea realizar una separación en entrenamiento y test previa a la búsqueda *grid*. Este patrón se suele denominar partición de entrenamiento, test y validación, y es bastante común en aprendizaje automático:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos emular este proceso fácilmente dividiendo primero los datos con ``train_test_split``, aplicando ``GridSearchCV`` al conjunto de entrenamiento, y calculando el ``score`` correspondiente solo con el conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar de nuevo los parámetros obtenidos con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
